input {
  syslog {
    port => 514
    host => "0.0.0.0"  # Bind to all interfaces
    type => "syslog"
  }
}

filter {
  # Basic syslog parsing - your original grok pattern is good
  grok {
    match => { 
      "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" 
    }
  }
  
  # Parse the timestamp into @timestamp field
  date {
    match => [ "syslog_timestamp", "MMM dd HH:mm:ss", "MMM  d HH:mm:ss" ]
    target => "@timestamp"
  }
  
  # Parse priority field (if present) to get facility and severity
  if [priority] {
    ruby {
      code => "
        priority = event.get('priority').to_i
        event.set('facility', priority >> 3)
        event.set('severity', priority & 7)
      "
    }
  }
  
  # Add some useful metadata
  mutate {
    add_field => { 
      "received_at" => "%{@timestamp}"
      "source_type" => "syslog"
    }
    # Clean up the original message field to avoid duplication
    copy => { "syslog_message" => "original_message" }
    replace => { "message" => "%{syslog_message}" }
  }
  
  # Remove temporary fields to keep the document clean
  mutate {
    remove_field => [ "syslog_message", "syslog_timestamp" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["http://es01:9200"]
    index => "syslog-%{+YYYY.MM.dd}"
    # Add document type for easier filtering
    template_name => "syslog"
  }
  
  # Also output to stdout for debugging (remove in production)
  stdout { 
    codec => rubydebug 
  }
}